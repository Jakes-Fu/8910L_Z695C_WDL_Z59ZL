中文联想字的思想，即根据日常使用的习惯，给出一个字后面出现概率大的字，按概率给出n个即可。
如果一个字很少或者没有后面跟的字，则给出常用字使用频率。
两个问题要解决：
1 常用字的使用频率统计。
2 任一字后字出现的概率统计。

为了完成这两个工作，我们写了一个脚本，去阅读一些常见的文档，统计字的出现次数以及字后面跟随的字及其频率。

目前的阅读素材是我们从yi-look上down下来的几百兆的小说、杂文等，应该符合一般人的汉字使用习惯。

不过我们有新的发现，即：按照上面的方式统计出来的联想字没有很强的“词性”，即一个字后面出现的概率很高的词极可能是跟其不能构成一个有意义的词，比如一些语气助词等。其实没有“词性”并不是很致命的事情，毕竟这个是更符合人们惯常的使用。

但是，我们还是为了突出词性，用另一种方式获得联想字：分解词库，将词库中的词作为联想字素材，这样，就是的联想字具备了极强的“词性”，如此一来，看上去好看多了。

具体的构造规则，详见脚本文件。